# Apache Kafka?

Apache Kafka는 분산형 스트리밍 플랫폼으로, 대규모 데이터를 안정적이고 실시간으로 처리할 수 있도록 설계된 시스템이다. 분산형 스트리밍 플랫폼이란 여러 컴퓨터나 노드에서 대규모 실시간 데이터를 수집, 전송, 저장, 처리하는 시스템을 의미한다. Kafka는 특히 대량의 이벤트 스트림 데이터를 처리하는 데 최적화되어 있으며, 높은 처리량과 낮은 지연 시간을 제공한다.

Kafka의 주요 기능은 실시간 데이터 스트리밍, 분산 저장, 그리고 데이터의 신뢰성 있는 전송을 보장하는 것이다. 이를 통해 다양한 데이터 소스로부터 실시간 데이터를 수집하고 분석하는 것이 가능하다.

# Why Kafka?

Kafka는 대규모 데이터 처리와 실시간 스트리밍, 확장성, 높은 성능을 이유로 주로 사용된다. 대용량 데이터를 빠르고 안정적으로 처리할 수 있을 뿐만 아니라, 실시간 데이터를 전달하는 데 있어서도 매우 높은 성능을 보인다. 특히 실시간 분석 및 모니터링 시스템 구축에 매우 적합하다.

Kafka는 분산형 시스템이기 때문에, 노드를 추가함으로써 쉽게 확장 가능하다. 브로커와 파티션의 개수를 조정함으로써 성능 저하 없이 수평적으로 확장할 수 있다. 또한, Kafka는 데이터를 빠르게 처리하고 전달하며, 클러스터 내에서 데이터를 분산 저장하기 때문에 성능이 매우 뛰어나다.

# Kafka's data transfer model

### Publish - Subscribe

카프카는 publish-subscribe 모델을 사용하여 데이터를 전송한다. 이 모델에서 프로듀서는 데이터를 Publish(게시) 하고, 컨슈머는 이를 Subscribe(구독) 하여 데이터를 읽는다. 한 번 게시된 데이터는 여러 컨슈머가 동시에 구독할 수 있어 동시 소비가 가능하다. 이 구조 덕분에 카프카는 다수의 소비자에서 병렬로 데이터를 전송할 수 있다. 

# Kafka architecture

## Cluster

클러스터는 여러 노드로 구성된 집합으로, 데이터를 저장하고 처리하는 역할을 한다.  프로듀서가 저장해야 할 데이터를 클러스터에 전달하면, 클러스터는 이를 보관하고 컨슈머가 순차적으로 처리한다. 하나의 클러스터 내부에는 여러 개의 브로커가 존재한다.

## Topic

카프카는 이벤트는 토픽이라는 단위로 구성된다. 토픽은 주제별로 관련된 이벤트를 분류하는 단위로, 프로듀서와 컨슈머는 토픽을 기준으로 데이터를 주고 받는다. 프로듀서가 특정 토픽에 데이터를 게시하면,해당 토픽을 구독하는 컨슈머가 데이터를 소비한다. 데이터는 순차적으로 기록되며, 여러 컨슈머가 동시에 데이터를 읽거나 저장할 수 있다. 

## Partition

각 토픽은 여러 파티션으로 나뉘며, 파티션은 데이터를 병렬로 처리할 수 있게 해주는 단위이다. 이러한 파티션 구조 덕분에 Kafka는 데이터를 순서대로 저장하면서도 병렬 처리를 할 수 있다. 

파티션은 append-only 파일로 동작하며, 각 데이터는 오프셋이라는 고유한 인덱스를 갖는다. 프로듀서는 데이터를 파티션의 맨 뒤에 추가하고, 컨슈머는 오프셋을 기준으로 데이터를 순차적으로 읽는다. 

## Broker

Kafka 브로커는 클러스터 내에서 프로듀서로부터 데이터를 수신하고 이를 파티션에 저장하는 서버다. 클러스터는 여러 브로커로 구성되며, 각 브로커는 일부 파티션을 관리하고 데이터를 디스크에 저장하여 데이터 손실을 방지한다. 브로커는 프로듀서로부터 전송된 데이터를 클러스터에 분산 저장하고, 컨슈머가 데이터를 소비할 수 있도록 한다.

## Producer

프로듀서는 데이터를 생성하고 Kafka 클러스터로 데이터를 전송하는 역할을 한다. 다양한 시스템에서 생성된 데이터를 카프카 클러스터로 전송하여 병렬 처리를 극대화한다. 프로듀서는 주어진 토픽으로 데이터를 게시하며, 게시된 데이터는 브로커에서 관리된다.

## Consumer

컨슈머는 Kafka에서 데이터를 소비하는 애플리케이션이다. 컨슈머는 특정 토픽을 구독하고, 해당 토픽의 파티션에서 데이터를 읽어 병렬로 처리한다. 여러 컨슈머가 동일한 토픽을 구독할 수 있어 다양한 데이터 처리 요구사항에 맞춰 동시 처리가 가능하다.

## Zookeeper

zookeeper 는 카프카 클러스터를 관리하고 조정하는 도구이다. 이는 브로커의 상태를 감시하고 브로커 간 상호작용을 관리한다. 하지만 최신 Kafka 버전에서는 Zookeeper 대신 Kafka Raft Protocol(KRaft)이 도입되었으며 zookeeper 의존성이 점차 줄어들고 있다.

# Kafka’s Workflow

카프카의 전체적인 동작 과정은 크게 데이터 생성(produce), 데이터 저장 및 분산(paritioning), 데이터 소비(consume) 로 나눌 수 있다. 

## producing data

데이터 스트림은 프로듀서가 데이터를 생성하는 것으로 시작된다. 다양한 시스템에서 생성된 이벤트나 로그 데이터는 카프카의 토픽으로 전송된다. 프로듀서는 데이터를 전송할 때 특정 토픽을 지정하고, 해당 토픽의 파티션에 데이터를 기록한다. 이때 프로듀서는 카프카 클러스터의 브로커와 통신하여 데이터를 전송한다. 

## storing and partitioning data

프로듀서가 전송한 데이터는 브로커에 의해 관리되는 파티션에 저장된다.  카프카는 데이터를 순차적으로 append-only 방식으로 기록하며, 병렬 처리를 위해 토픽이 여러 파티션으로 분할된다. 파티션의 데이터는 브로커에 의해 디스크에 저장되며, 장애 발생 시에도 데이터 손실을 방지한다. 

## consuming Data

컨슈머는 특정 토픽을 구독하고 파티션에 저장된 데이터를 읽어간다. 컨슈머는 자신의 오프셋을 관리하여 데이터의 소비 위치를 추적하며 이를 통해 특정 시점의 데이터를 반복적으로 읽거나 이어서 읽을 수 있다. 여러 컨슈머가 동일한 토픽을 구독하면 데이터를 병렬로 처리할 수 있다.

## metadata management

카프카는 클러스터 내에서 발생하는 메타데이터( 파티션 정보, 브로커 상태 등) 를 관리하기 위해서 KRaft 또는 Zookeeper 를 사용한다. 

최신 Kafka 버전에서는 KRaft가 Zookeeper를 대체하며, Kafka 클러스터 내에서 리더 선출과 메타데이터 관리 기능을 수행한다.

## processing and streaming Data

카프카는 단순한 데이터 전송하고 소비기능 외에도 추가로 실시간으로 데이터를 처리할 수 있는 기능을 제공한다. Kafka Streams는 실시간으로 데이터를 처리할 수 있는 라이브러리이며, Flink, Spark Streaming, Storm과 같은 다른 스트리밍 처리 엔진과 통합될 수 있다.

# Kafka for Edge

edge computing 은 데이터가 생성되는 장소 ( ex 센서, IoT 기기 등) 가까운 곳에서 데이터를 처리하는 분산 컴퓨팅 방식이다. 중앙 데이터 센터로 데이터를 모두 전송하여 처리하는 대신, edge 에서 데이터를 처리함으로써 지연 시간을 줄이고 네트워크 트래픽을 감소시킨다. 

엣지 컴퓨팅 환경에서는 하나의 노드에서 여러 서비스가 동시에 호스팅될 수 있으며, 각 서비스는 서로 다른 중요도와 우선순위를 가질 수 있다.

카프카는 기본적으로 FIFO 방식으로 데이터를 처리하는 시스템이다. 모든 요청을 같은 우선순위로 처리하기 때문에, 높은 우선순위를 가진 요청이 다른 서비스의 요청에 의해 지연될 수 있다. 이를 해결하기 위해 우선순위 기반 처리를 구현하는 것이 필요하다.